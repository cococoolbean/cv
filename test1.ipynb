{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    " \n",
    "# Read the original image\n",
    "img = cv2.imread('top_view.jpg') \n",
    "# Display original image\n",
    "cv2.imshow('Original', img)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# Convert to graycsale\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Blur the image for better edge detection\n",
    "img_blur = cv2.GaussianBlur(img_gray, (3,3), 0) \n",
    " \n",
    "# Sobel Edge Detection\n",
    "sobelx = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5) # Sobel Edge Detection on the X axis\n",
    "sobely = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5) # Sobel Edge Detection on the Y axis\n",
    "sobelxy = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5) # Combined X and Y Sobel Edge Detection\n",
    "# Display Sobel Edge Detection Images\n",
    "cv2.imshow('Sobel X', sobelx)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel Y', sobely)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel X Y using Sobel() function', sobelxy)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# Canny Edge Detection\n",
    "edges = cv2.Canny(image=img_blur, threshold1=100, threshold2=200) # Canny Edge Detection\n",
    "# Display Canny Edge Detection Image\n",
    "cv2.imshow('Canny Edge Detection', edges)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m out \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m, fourcc, \u001b[38;5;241m20.0\u001b[39m, (frame_width, frame_height))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Convert frame to grayscale\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open the default camera\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Get the default frame width and height\n",
    "frame_width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Perform Canny edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    # Find contours in the edge-detected image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Find the largest contour and get its bounding box\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        \n",
    "        # Draw the bounding box on the original frame\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Write the frame to the output file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Bounding Box', frame)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and writer objects\n",
    "cam.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBounding Box\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# Press 'q' to exit the loop\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Release the capture and writer objects\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open the default camera\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Get the default frame width and height\n",
    "frame_width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding to detect box shape\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours based on area to avoid small contours (like text)\n",
    "    min_area = 10000  # Adjust this threshold based on the object size\n",
    "    box_contours = [c for c in contours if cv2.contourArea(c) > min_area]\n",
    "    \n",
    "    # Draw the bounding box around the largest contour that likely represents the box\n",
    "    if box_contours:\n",
    "        largest_contour = max(box_contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Write the frame to the output file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Bounding Box', frame)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and writer objects\n",
    "cam.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m: \n\u001b[1;32m---> 52\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 21\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: \n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Read a frame from the webcam \u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret: \n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage not captured\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def canny_edge_detection(frame): \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(src=gray, ksize=(5, 5), sigmaX=1.0)\n",
    "    edges = cv2.Canny(blurred, 50, 120)  # Adjusted Canny thresholds\n",
    "    return blurred, edges\n",
    "\n",
    "def main(): \n",
    "    # Open the default webcam  \n",
    "    cap = cv2.VideoCapture(0)\n",
    "      \n",
    "    while True: \n",
    "        # Read a frame from the webcam \n",
    "        ret, frame = cap.read() \n",
    "        if not ret: \n",
    "            print('Image not captured') \n",
    "            break\n",
    "          \n",
    "        # Perform Canny edge detection on the frame \n",
    "        blurred, edges = canny_edge_detection(frame)\n",
    "\n",
    "        # Find contours based on the edges detected\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Draw bounding boxes around detected contours\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > 500:  # Filter out small contours based on area\n",
    "                x, y, w, h = cv2.boundingRect(contour)  # Get the bounding box coordinates\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw rectangle on original frame\n",
    "        \n",
    "        # Display the original frame with bounding boxes\n",
    "        cv2.imshow(\"Original with Bounding Boxes\", frame)\n",
    "        cv2.imshow(\"Blurred\", blurred)\n",
    "        cv2.imshow(\"Edges\", edges)\n",
    "          \n",
    "        # Exit the loop when 'q' key is pressed \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "            break\n",
    "      \n",
    "    # Release the webcam and close the windows \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 81\u001b[0m\n\u001b[0;32m     78\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m: \n\u001b[1;32m---> 81\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 37\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: \n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Read a frame from the webcam\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage not captured\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# Parameters for smoothing\n",
    "SMOOTHING_FRAMES = 10  # Number of frames to average over\n",
    "contour_history = deque(maxlen=SMOOTHING_FRAMES)  # Store the last N bounding box positions\n",
    "\n",
    "def canny_edge_detection(frame): \n",
    "    # Convert the frame to grayscale for edge detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Gaussian blur to reduce noise and smoothen edges\n",
    "    blurred = cv2.GaussianBlur(src=gray, ksize=(5, 5), sigmaX=1.0)\n",
    "    # Perform Canny edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 120)  # Adjusted Canny thresholds\n",
    "    return blurred, edges\n",
    "\n",
    "def average_bounding_boxes(bounding_boxes):\n",
    "    \"\"\"Average the positions of bounding boxes.\"\"\"\n",
    "    if not bounding_boxes:\n",
    "        return None\n",
    "    \n",
    "    # Compute the average bounding box by averaging x, y, w, h values\n",
    "    x_avg = int(np.mean([box[0] for box in bounding_boxes]))\n",
    "    y_avg = int(np.mean([box[1] for box in bounding_boxes]))\n",
    "    w_avg = int(np.mean([box[2] for box in bounding_boxes]))\n",
    "    h_avg = int(np.mean([box[3] for box in bounding_boxes]))\n",
    "    \n",
    "    return (x_avg, y_avg, w_avg, h_avg)\n",
    "\n",
    "def main(): \n",
    "    # Open the default webcam  \n",
    "    cap = cv2.VideoCapture(0)\n",
    "      \n",
    "    while True: \n",
    "        # Read a frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print('Image not captured')\n",
    "            break\n",
    "        \n",
    "        # Perform Canny edge detection on the frame\n",
    "        blurred, edges = canny_edge_detection(frame)\n",
    "        \n",
    "        # Find contours based on the edges detected\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Collect bounding boxes of large enough contours\n",
    "        frame_bounding_boxes = []\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > 500:  # Increased contour area threshold\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                frame_bounding_boxes.append((x, y, w, h))\n",
    "        \n",
    "        # Add bounding boxes for the current frame to the history\n",
    "        if frame_bounding_boxes:\n",
    "            contour_history.append(frame_bounding_boxes[0])  # Only store the largest contour (first in list)\n",
    "        \n",
    "        # Calculate the smoothed bounding box if we have enough data\n",
    "        if len(contour_history) >= SMOOTHING_FRAMES:\n",
    "            averaged_box = average_bounding_boxes(contour_history)\n",
    "            if averaged_box:\n",
    "                x, y, w, h = averaged_box\n",
    "                # Draw the averaged bounding box on the original frame\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Display the original frame with bounding boxes\n",
    "        cv2.imshow(\"Original with Smoothed Bounding Boxes\", frame)\n",
    "        cv2.imshow(\"Blurred\", blurred)\n",
    "        cv2.imshow(\"Edges\", edges)\n",
    "        \n",
    "        # Exit the loop when 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "      \n",
    "    # Release the webcam and close the windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1367: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvWaitKey'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m gray_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(gray_frame, (\u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m21\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Set background frame when '1' is pressed\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     20\u001b[0m     background \u001b[38;5;241m=\u001b[39m gray_frame\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackground captured\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1367: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvWaitKey'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "background = None\n",
    "\n",
    "while True:\n",
    "    # Read frame from webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "    # Set background frame when '1' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('1'):\n",
    "        background = gray_frame\n",
    "        print(\"Background captured\")\n",
    "        continue\n",
    "    \n",
    "    # Check if background is set\n",
    "    if background is not None:\n",
    "        # Compute absolute difference between background and current frame\n",
    "        frame_delta = cv2.absdiff(background, gray_frame)\n",
    "        \n",
    "        # Apply threshold to get binary image of the difference\n",
    "        thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "        \n",
    "        # Dilate thresholded image to fill in holes, then find contours\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Loop over contours and draw bounding boxes\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < 500:  # Filter small contours\n",
    "                continue\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Optional: Show the threshold and delta images for debugging\n",
    "        cv2.imshow(\"Threshold\", thresh)\n",
    "        cv2.imshow(\"Frame Delta\", frame_delta)\n",
    "    \n",
    "    # Display the resulting frame with bounding boxes\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Exit when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Release resources\u001b[39;00m\n\u001b[0;32m     55\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m---> 56\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdestroyAllWindows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "background = None\n",
    "\n",
    "while True:\n",
    "    # Read frame from webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "    # Set background frame when '1' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('1'):\n",
    "        background = gray_frame\n",
    "        print(\"Background captured\")\n",
    "        continue\n",
    "    \n",
    "    # Check if background is set\n",
    "    if background is not None:\n",
    "        # Compute absolute difference between background and current frame\n",
    "        frame_delta = cv2.absdiff(background, gray_frame)\n",
    "        \n",
    "        # Apply threshold to get binary image of the difference\n",
    "        thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "        \n",
    "        # Dilate thresholded image to fill in holes, then find contours\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Loop over contours and draw bounding boxes\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < 500:  # Filter small contours\n",
    "                continue\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Optional: Show the threshold and delta images for debugging\n",
    "        cv2.imshow(\"Threshold\", thresh)\n",
    "        cv2.imshow(\"Frame Delta\", frame_delta)\n",
    "    \n",
    "    # Display the resulting frame with bounding boxes\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Exit when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m cam\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Convert frame to grayscale\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Apply Gaussian blur to reduce noise\u001b[39;00m\n\u001b[0;32m     22\u001b[0m blurred \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(gray, (\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open the default camera\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Get the default frame width and height\n",
    "frame_width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding to detect box shape\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours based on area to avoid small contours (like text)\n",
    "    min_area = 100  # Adjust this threshold based on the object size\n",
    "    box_contours = [c for c in contours if cv2.contourArea(c) > min_area]\n",
    "    \n",
    "    # Draw the bounding box around the largest contour that likely represents the box\n",
    "    if box_contours:\n",
    "        largest_contour = max(box_contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Write the frame to the output file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Bounding Box', frame)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and writer objects\n",
    "cam.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# Exit when 'q' is pressed\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Release resources\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "background = None\n",
    "\n",
    "while True:\n",
    "    # Read frame from webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "    # Set background frame when '1' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('1'):\n",
    "        background = gray_frame\n",
    "        print(\"Background captured\")\n",
    "        continue\n",
    "    \n",
    "    # Check if background is set\n",
    "    if background is not None:\n",
    "        # Compute absolute difference between background and current frame\n",
    "        frame_delta = cv2.absdiff(background, gray_frame)\n",
    "        \n",
    "        # Apply threshold to get binary image of the difference\n",
    "        thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "        \n",
    "        # Dilate thresholded image to fill in holes, then find contours\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Loop over contours and draw bounding boxes\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < 500:  # Filter small contours\n",
    "                continue\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Optional: Show the threshold and delta images for debugging\n",
    "        cv2.imshow(\"Threshold\", thresh)\n",
    "        cv2.imshow(\"Frame Delta\", frame_delta)\n",
    "    \n",
    "    # Display the resulting frame with bounding boxes\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Exit when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.aruco' has no attribute 'drawMarker'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Generate the marker\u001b[39;00m\n\u001b[0;32m     12\u001b[0m marker_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((marker_size, marker_size), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m---> 13\u001b[0m marker_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maruco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrawMarker\u001b[49m(aruco_dict, marker_id, marker_size, marker_image, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Save the marker image\u001b[39;00m\n\u001b[0;32m     16\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maruco_marker_42.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, marker_image)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.aruco' has no attribute 'drawMarker'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Use getPredefinedDictionary instead of Dictionary_get\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "\n",
    "# Define the marker ID and size\n",
    "marker_id = 42\n",
    "marker_size = 200\n",
    "\n",
    "# Generate the marker\n",
    "marker_image = np.zeros((marker_size, marker_size), dtype=np.uint8)\n",
    "marker_image = cv2.aruco.drawMarker(aruco_dict, marker_id, marker_size, marker_image, 1)\n",
    "\n",
    "# Save the marker image\n",
    "cv2.imwrite(\"aruco_marker_42.png\", marker_image)\n",
    "print(\"ArUco marker saved as aruco_marker_42.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Camera Pixels per cm: 53.333333333333336\n",
      "Front Camera Pixels per cm: 42.666666666666664\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Known length of the ruler in centimeters\n",
    "KNOWN_LENGTH_CM = 12.0  # Adjust to the actual length of the ruler you are using\n",
    "\n",
    "# Initialize the top and front cameras\n",
    "cap_top = cv2.VideoCapture(0)  # Adjust index for the top camera\n",
    "cap_front = cv2.VideoCapture(1)  # Adjust index for the front camera\n",
    "\n",
    "# Function to calculate pixels per metric\n",
    "def calculate_pixels_per_metric(frame, known_length_cm):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Find the largest contour (assuming it's the ruler)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Calculate bounding box width\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    \n",
    "    # Assume the ruler is aligned with the width or height\n",
    "    ruler_length_px = max(w, h)\n",
    "    \n",
    "    # Calculate pixels per metric (pixels per cm)\n",
    "    pixels_per_metric = ruler_length_px / known_length_cm\n",
    "    return pixels_per_metric\n",
    "\n",
    "# Capture a frame for calibration from each camera\n",
    "ret_top, frame_top = cap_top.read()\n",
    "ret_front, frame_front = cap_front.read()\n",
    "\n",
    "# Calculate pixels per metric for each camera\n",
    "if ret_top and ret_front:\n",
    "    pixels_per_metric_top = calculate_pixels_per_metric(frame_top, 12.0)\n",
    "    pixels_per_metric_front = calculate_pixels_per_metric(frame_front, 15.0)\n",
    "    \n",
    "    print(f\"Top Camera Pixels per cm: {pixels_per_metric_top}\")\n",
    "    print(f\"Front Camera Pixels per cm: {pixels_per_metric_front}\")\n",
    "\n",
    "# Release cameras after calibration\n",
    "cap_top.release()\n",
    "cap_front.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m gray_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(gray_frame, (\u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m21\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Set background frame when '1' is pressed\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     20\u001b[0m     background \u001b[38;5;241m=\u001b[39m gray_frame\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackground captured\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "background = None\n",
    "\n",
    "while True:\n",
    "    # Read frame from webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "    # Set background frame when '1' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('1'):\n",
    "        background = gray_frame\n",
    "        print(\"Background captured\")\n",
    "        continue\n",
    "    \n",
    "    # Check if background is set\n",
    "    if background is not None:\n",
    "        # Compute absolute difference between background and current frame\n",
    "        frame_delta = cv2.absdiff(background, gray_frame)\n",
    "        \n",
    "        # Apply threshold to get binary image of the difference\n",
    "        thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "        \n",
    "        # Dilate thresholded image to fill in holes, then find contours\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Loop over contours and draw bounding boxes\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < 500:  # Filter small contours\n",
    "                continue\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Optional: Show the threshold and delta images for debugging\n",
    "        cv2.imshow(\"Threshold\", thresh)\n",
    "        cv2.imshow(\"Frame Delta\", frame_delta)\n",
    "    \n",
    "    # Display the resulting frame with bounding boxes\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Exit when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background for Camera 2 captured\n",
      "Background for Camera 1 captured\n",
      "Background for Camera 2 captured\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackground for Camera 1 captured\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Capture background frame when '2' is pressed for camera 2\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     56\u001b[0m     background2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame2, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     57\u001b[0m     background2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(background2, (\u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m21\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize two webcams for top and front views\n",
    "cap1 = cv2.VideoCapture(0)  # Camera 1 (Top view)\n",
    "cap2 = cv2.VideoCapture(1)  # Camera 2 (Front view)\n",
    "\n",
    "background1 = None\n",
    "background2 = None\n",
    "\n",
    "def process_frame(frame, background):\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "    if background is None:\n",
    "        return frame, background, None, None\n",
    "\n",
    "    # Compute absolute difference between background and current frame\n",
    "    frame_delta = cv2.absdiff(background, gray_frame)\n",
    "    \n",
    "    # Apply threshold to get binary image of the difference\n",
    "    thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    # Dilate thresholded image to fill in holes, then find contours\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Find the largest contour and create bounding box around it\n",
    "    max_area = 0\n",
    "    bounding_box = None\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 500 and area > max_area:  # Filter small contours and track largest\n",
    "            max_area = area\n",
    "            bounding_box = cv2.boundingRect(contour)\n",
    "            (x, y, w, h) = bounding_box\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    return frame, background, bounding_box, max_area\n",
    "\n",
    "while True:\n",
    "    # Read frames from both cameras\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "    if not ret1 or not ret2:\n",
    "        break\n",
    "\n",
    "    # Capture background frame when '1' is pressed for camera 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('1'):\n",
    "        background1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        background1 = cv2.GaussianBlur(background1, (21, 21), 0)\n",
    "        print(\"Background for Camera 1 captured\")\n",
    "\n",
    "    # Capture background frame when '2' is pressed for camera 2\n",
    "    if cv2.waitKey(1) & 0xFF == ord('2'):\n",
    "        background2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "        background2 = cv2.GaussianBlur(background2, (21, 21), 0)\n",
    "        print(\"Background for Camera 2 captured\")\n",
    "\n",
    "    # Process frames for each camera\n",
    "    frame1, _, bbox1, area1 = process_frame(frame1, background1)\n",
    "    frame2, _, bbox2, area2 = process_frame(frame2, background2)\n",
    "\n",
    "    # Estimate size if bounding boxes are detected in both views\n",
    "    if bbox1 is not None and bbox2 is not None:\n",
    "        # Extract dimensions from bounding boxes\n",
    "        width_top, height_top = bbox1[2], bbox1[3]\n",
    "        width_side, height_side = bbox2[2], bbox2[3]\n",
    "\n",
    "        # Simple estimation of size using average of the dimensions\n",
    "        estimated_width = (width_top + width_side) / 2\n",
    "        estimated_height = (height_top + height_side) / 2\n",
    "\n",
    "        # Display estimated dimensions on the front view frame\n",
    "        cv2.putText(frame2, f\"Est. Width: {estimated_width:.2f}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        cv2.putText(frame2, f\"Est. Height: {estimated_height:.2f}\", (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "    # Display the frames\n",
    "    cv2.imshow(\"Top View\", frame1)\n",
    "    cv2.imshow(\"Front View\", frame2)\n",
    "\n",
    "    # Exit when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Read frame from webcam\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read frame from webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert frame to grayscale and apply Gaussian blur\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "    \n",
    "    # Apply edge detection\n",
    "    edges = cv2.Canny(gray_frame, 50, 150)\n",
    "    \n",
    "    # Find contours based on the edges\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Find the largest contour by area\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Get the bounding box coordinates of the largest contour\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        \n",
    "        # Draw the bounding box on the frame\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame with bounding box\n",
    "    cv2.imshow(\"Tracked Object\", frame)\n",
    "\n",
    "    # Exit when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m _, thresh_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(diff_frame, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Find edges using Canny\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m edges \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCanny\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthresh_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Find contours in the edge-detected frame\u001b[39;00m\n\u001b[0;32m     38\u001b[0m contours, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindContours(edges, cv2\u001b[38;5;241m.\u001b[39mRETR_EXTERNAL, cv2\u001b[38;5;241m.\u001b[39mCHAIN_APPROX_SIMPLE)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Capture background frame (assuming the scene is empty initially)\n",
    "ret, background = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to capture background frame\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "# Convert background frame to grayscale\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background_gray = cv2.GaussianBlur(background_gray, (21, 21), 0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Capture current frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "    # Compute absolute difference between background and current frame\n",
    "    diff_frame = cv2.absdiff(background_gray, gray_frame)\n",
    "\n",
    "    # Apply threshold to get binary image\n",
    "    _, thresh_frame = cv2.threshold(diff_frame, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find edges using Canny\n",
    "    edges = cv2.Canny(thresh_frame, 50, 150)\n",
    "\n",
    "    # Find contours in the edge-detected frame\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Copy the original frame to draw the contours and bounding box\n",
    "    frame_with_contours = frame.copy()\n",
    "\n",
    "    # Draw all contours on the frame\n",
    "    cv2.drawContours(frame_with_contours, contours, -1, (255, 0, 0), 2)\n",
    "\n",
    "    # Find the largest contour by area\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour) > 500:  # Filter small contours\n",
    "            # Get bounding box for the largest contour\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            # Draw the bounding box on the frame\n",
    "            cv2.rectangle(frame_with_contours, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Show each processing step in a separate window\n",
    "    cv2.imshow(\"Original Frame\", frame)\n",
    "    cv2.imshow(\"Difference Frame\", diff_frame)\n",
    "    cv2.imshow(\"Threshold Frame\", thresh_frame)\n",
    "    cv2.imshow(\"Edges\", edges)\n",
    "    cv2.imshow(\"Contours and Bounding Box\", frame_with_contours)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m bbox \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Capture current frame\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Capture background frame (assuming the scene is empty initially)\n",
    "ret, background = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to capture background frame\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "# Convert background frame to grayscale\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background_gray = cv2.GaussianBlur(background_gray, (21, 21), 0)\n",
    "\n",
    "# Variables to store bounding box state\n",
    "tracking = False\n",
    "bbox = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Capture current frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "    if not tracking:\n",
    "        # Calculate absolute difference to detect an initial object\n",
    "        diff_frame = cv2.absdiff(background_gray, gray_frame)\n",
    "        _, thresh_frame = cv2.threshold(diff_frame, 25, 255, cv2.THRESH_BINARY)\n",
    "        edges = cv2.Canny(thresh_frame, 50, 150)\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Detect the largest contour to initialize tracking\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            if cv2.contourArea(largest_contour) > 500:  # Adjust area filter as needed\n",
    "                bbox = cv2.boundingRect(largest_contour)  # (x, y, w, h)\n",
    "                tracking = True\n",
    "\n",
    "    else:\n",
    "        # When tracking, update bounding box using template matching\n",
    "        x, y, w, h = bbox\n",
    "        object_region = gray_frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Use template matching to find the new location of the object\n",
    "        res = cv2.matchTemplate(gray_frame, object_region, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "        # Update the bounding box location\n",
    "        x, y = max_loc\n",
    "        bbox = (x, y, w, h)\n",
    "\n",
    "    # Draw the updated bounding box on the frame\n",
    "    if bbox is not None:\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow(\"Object Tracking\", frame)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m background_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(background_gray, (\u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m21\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Capture current frame\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Capture background frame (assuming the scene is empty initially)\n",
    "ret, background = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to capture background frame\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "# Convert background frame to grayscale\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background_gray = cv2.GaussianBlur(background_gray, (21, 21), 0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Capture current frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "    # Compute absolute difference between background and current frame\n",
    "    diff_frame = cv2.absdiff(background_gray, gray_frame)\n",
    "\n",
    "    # Apply threshold to get binary image\n",
    "    _, thresh_frame = cv2.threshold(diff_frame, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find edges using Canny\n",
    "    edges = cv2.Canny(thresh_frame, 50, 150)\n",
    "\n",
    "    # Find contours in the edge-detected frame\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the largest contour by area\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour) > 500:  # Filter small contours\n",
    "            # Get bounding box for the largest contour\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            # Draw the bounding box on the frame\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow(\"Bounding Box Tracking\", frame)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m  \u001b[38;5;66;03m# Smoothing factor for bounding box (0 < alpha < 1)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Capture current frame\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Capture background frame (assuming the scene is empty initially)\n",
    "ret, background = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to capture background frame\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "# Convert background frame to grayscale\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background_gray = cv2.GaussianBlur(background_gray, (21, 21), 0)\n",
    "\n",
    "# Variables for bounding box stabilization\n",
    "prev_x, prev_y, prev_w, prev_h = 0, 0, 0, 0\n",
    "alpha = 0.7  # Smoothing factor for bounding box (0 < alpha < 1)\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Capture current frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "    # Compute absolute difference between background and current frame\n",
    "    diff_frame = cv2.absdiff(background_gray, gray_frame)\n",
    "\n",
    "    # Apply threshold to get binary image\n",
    "    _, thresh_frame = cv2.threshold(diff_frame, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find edges using Canny\n",
    "    edges = cv2.Canny(thresh_frame, 50, 150)\n",
    "\n",
    "    # Find contours in the edge-detected frame\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Copy the original frame to draw the contours and bounding box\n",
    "    frame_with_contours = frame.copy()\n",
    "\n",
    "    # Draw all contours on the frame\n",
    "    cv2.drawContours(frame_with_contours, contours, -1, (255, 0, 0), 2)\n",
    "\n",
    "    # Find the largest contour by area\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        contour_area = cv2.contourArea(largest_contour)\n",
    "        \n",
    "        # Apply a minimum area filter to ignore small changes\n",
    "        if contour_area > 1000:  # Adjust the threshold based on your scenario\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            \n",
    "            # Stabilize bounding box using a moving average\n",
    "            x = int(alpha * x + (1 - alpha) * prev_x)\n",
    "            y = int(alpha * y + (1 - alpha) * prev_y)\n",
    "            w = int(alpha * w + (1 - alpha) * prev_w)\n",
    "            h = int(alpha * h + (1 - alpha) * prev_h)\n",
    "            \n",
    "            # Update previous bounding box coordinates\n",
    "            prev_x, prev_y, prev_w, prev_h = x, y, w, h\n",
    "            \n",
    "            # Draw the stabilized bounding box\n",
    "            cv2.rectangle(frame_with_contours, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Show each processing step in a separate window\n",
    "    cv2.imshow(\"Original Frame\", frame)\n",
    "    cv2.imshow(\"Difference Frame\", diff_frame)\n",
    "    cv2.imshow(\"Threshold Frame\", thresh_frame)\n",
    "    cv2.imshow(\"Edges\", edges)\n",
    "    cv2.imshow(\"Contours and Bounding Box\", frame_with_contours)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m stabilize_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m  \u001b[38;5;66;03m# Threshold for bounding box stabilization\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Capture current frame\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Capture background frame (assuming the scene is empty initially)\n",
    "ret, background = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to capture background frame\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "# Convert background frame to grayscale\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background_gray = cv2.GaussianBlur(background_gray, (21, 21), 0)\n",
    "\n",
    "# Initialize previous bounding box dimensions for comparison\n",
    "prev_box = None\n",
    "stabilize_threshold = 50  # Threshold for bounding box stabilization\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Capture current frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "    # Compute absolute difference between background and current frame\n",
    "    diff_frame = cv2.absdiff(background_gray, gray_frame)\n",
    "\n",
    "    # Apply threshold to get binary image\n",
    "    _, thresh_frame = cv2.threshold(diff_frame, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find edges using Canny\n",
    "    edges = cv2.Canny(thresh_frame, 50, 150)\n",
    "\n",
    "    # Find contours in the edge-detected frame\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the largest contour by area\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        contour_area = cv2.contourArea(largest_contour)\n",
    "        \n",
    "        if contour_area > 500:  # Filter small contours\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "            # Stabilization: check if new bounding box is close to the previous one\n",
    "            if prev_box:\n",
    "                prev_x, prev_y, prev_w, prev_h = prev_box\n",
    "                distance = np.sqrt((x - prev_x) ** 2 + (y - prev_y) ** 2)\n",
    "                \n",
    "                # Update the bounding box only if it moves significantly\n",
    "                if distance > stabilize_threshold:\n",
    "                    prev_box = (x, y, w, h)\n",
    "            else:\n",
    "                # Initialize the previous bounding box\n",
    "                prev_box = (x, y, w, h)\n",
    "\n",
    "            # Draw the bounding box on the frame\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow(\"Bounding Box Tracking\", frame)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m background_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(background_gray, (\u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m21\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Capture current frame\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Capture background frame (assuming the scene is empty initially)\n",
    "ret, background = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to capture background frame\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "# Convert background frame to grayscale\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background_gray = cv2.GaussianBlur(background_gray, (21, 21), 0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Capture current frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "\n",
    "    # Compute absolute difference between background and current frame\n",
    "    diff_frame = cv2.absdiff(background_gray, gray_frame)\n",
    "\n",
    "    # Apply threshold to get binary image\n",
    "    _, thresh_frame = cv2.threshold(diff_frame, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find edges using Canny\n",
    "    edges = cv2.Canny(thresh_frame, 50, 150)\n",
    "\n",
    "    # Find contours in the edge-detected frame\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the largest contour by area\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour) > 500:  # Filter small contours\n",
    "            # Get bounding box for the largest contour\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            # Draw the bounding box on the frame\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow(\"Bounding Box Tracking\", frame)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'width_front_cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 81\u001b[0m\n\u001b[0;32m     77\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(frame_top, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWidth: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwidth_top_cm\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cm, Height: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheight_top_cm\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     78\u001b[0m                 (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.6\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m contours_front:\n\u001b[1;32m---> 81\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(frame_front, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWidth: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mwidth_front_cm\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cm, Height: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheight_front_cm\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     82\u001b[0m                 (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.6\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Exit on pressing 'q'\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'width_front_cm' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the webcams for top and front views\n",
    "cap_top = cv2.VideoCapture(0)  # Adjust ID if necessary for the top camera\n",
    "cap_front = cv2.VideoCapture(1)  # Adjust ID if necessary for the front camera\n",
    "\n",
    "# Capture background frames for both cameras (assuming the scene is empty initially)\n",
    "ret_top, background_top = cap_top.read()\n",
    "ret_front, background_front = cap_front.read()\n",
    "if not (ret_top and ret_front):\n",
    "    print(\"Failed to capture background frames\")\n",
    "    cap_top.release()\n",
    "    cap_front.release()\n",
    "    exit()\n",
    "\n",
    "# Convert background frames to grayscale\n",
    "background_top_gray = cv2.cvtColor(background_top, cv2.COLOR_BGR2GRAY)\n",
    "background_top_gray = cv2.GaussianBlur(background_top_gray, (21, 21), 0)\n",
    "\n",
    "background_front_gray = cv2.cvtColor(background_front, cv2.COLOR_BGR2GRAY)\n",
    "background_front_gray = cv2.GaussianBlur(background_front_gray, (21, 21), 0)\n",
    "\n",
    "# Scaling factors (cm per pixel), replace with actual calibration values\n",
    "scale_top = 0.1  # Example scaling factor for top camera\n",
    "scale_front = 0.1  # Example scaling factor for front camera\n",
    "\n",
    "while cap_top.isOpened() and cap_front.isOpened():\n",
    "    # Capture current frames from both cameras\n",
    "    ret_top, frame_top = cap_top.read()\n",
    "    ret_front, frame_front = cap_front.read()\n",
    "    if not (ret_top and ret_front):\n",
    "        break\n",
    "\n",
    "    # Process the top camera frame\n",
    "    gray_top = cv2.cvtColor(frame_top, cv2.COLOR_BGR2GRAY)\n",
    "    gray_top = cv2.GaussianBlur(gray_top, (21, 21), 0)\n",
    "    diff_top = cv2.absdiff(background_top_gray, gray_top)\n",
    "    _, thresh_top = cv2.threshold(diff_top, 25, 255, cv2.THRESH_BINARY)\n",
    "    edges_top = cv2.Canny(thresh_top, 50, 150)\n",
    "    contours_top, _ = cv2.findContours(edges_top, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Process the front camera frame\n",
    "    gray_front = cv2.cvtColor(frame_front, cv2.COLOR_BGR2GRAY)\n",
    "    gray_front = cv2.GaussianBlur(gray_front, (21, 21), 0)\n",
    "    diff_front = cv2.absdiff(background_front_gray, gray_front)\n",
    "    _, thresh_front = cv2.threshold(diff_front, 25, 255, cv2.THRESH_BINARY)\n",
    "    edges_front = cv2.Canny(thresh_front, 50, 150)\n",
    "    contours_front, _ = cv2.findContours(edges_front, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the largest contour and bounding box for top camera\n",
    "    if contours_top:\n",
    "        largest_contour_top = max(contours_top, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour_top) > 500:  # Filter small contours\n",
    "            x_top, y_top, w_top, h_top = cv2.boundingRect(largest_contour_top)\n",
    "            # Draw bounding box and calculate real-world size for top camera\n",
    "            cv2.rectangle(frame_top, (x_top, y_top), (x_top + w_top, y_top + h_top), (0, 255, 0), 2)\n",
    "            width_top_cm = w_top * scale_top\n",
    "            height_top_cm = h_top * scale_top\n",
    "\n",
    "    # Find the largest contour and bounding box for front camera\n",
    "    if contours_front:\n",
    "        largest_contour_front = max(contours_front, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour_front) > 500:  # Filter small contours\n",
    "            x_front, y_front, w_front, h_front = cv2.boundingRect(largest_contour_front)\n",
    "            # Draw bounding box and calculate real-world size for front camera\n",
    "            cv2.rectangle(frame_front, (x_front, y_front), (x_front + w_front, y_front + h_front), (255, 0, 0), 2)\n",
    "            width_front_cm = w_front * scale_front\n",
    "            height_front_cm = h_front * scale_front\n",
    "\n",
    "    # Display results\n",
    "    cv2.imshow(\"Top Camera - Bounding Box Tracking\", frame_top)\n",
    "    cv2.imshow(\"Front Camera - Bounding Box Tracking\", frame_front)\n",
    "\n",
    "    # Display the real-world size on the frames\n",
    "    if contours_top:\n",
    "        cv2.putText(frame_top, f\"Width: {width_top_cm:.2f} cm, Height: {height_top_cm:.2f} cm\",\n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    if contours_front:\n",
    "        cv2.putText(frame_front, f\"Width: {width_front_cm:.2f} cm, Height: {height_front_cm:.2f} cm\",\n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap_top.release()\n",
    "cap_front.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the webcams for top and front views\n",
    "cap_top = cv2.VideoCapture(0)  # Adjust ID if necessary for the top camera\n",
    "cap_front = cv2.VideoCapture(1)  # Adjust ID if necessary for the front camera\n",
    "\n",
    "# Capture background frames for both cameras (assuming the scene is empty initially)\n",
    "ret_top, background_top = cap_top.read()\n",
    "ret_front, background_front = cap_front.read()\n",
    "if not (ret_top and ret_front):\n",
    "    print(\"Failed to capture background frames\")\n",
    "    cap_top.release()\n",
    "    cap_front.release()\n",
    "    exit()\n",
    "\n",
    "# Convert background frames to grayscale\n",
    "background_top_gray = cv2.cvtColor(background_top, cv2.COLOR_BGR2GRAY)\n",
    "background_top_gray = cv2.GaussianBlur(background_top_gray, (21, 21), 0)\n",
    "\n",
    "background_front_gray = cv2.cvtColor(background_front, cv2.COLOR_BGR2GRAY)\n",
    "background_front_gray = cv2.GaussianBlur(background_front_gray, (21, 21), 0)\n",
    "\n",
    "while cap_top.isOpened() and cap_front.isOpened():\n",
    "    # Capture current frames from both cameras\n",
    "    ret_top, frame_top = cap_top.read()\n",
    "    ret_front, frame_front = cap_front.read()\n",
    "    if not (ret_top and ret_front):\n",
    "        break\n",
    "\n",
    "    # Process the top camera frame\n",
    "    gray_top = cv2.cvtColor(frame_top, cv2.COLOR_BGR2GRAY)\n",
    "    gray_top = cv2.GaussianBlur(gray_top, (21, 21), 0)\n",
    "    diff_top = cv2.absdiff(background_top_gray, gray_top)\n",
    "    _, thresh_top = cv2.threshold(diff_top, 25, 255, cv2.THRESH_BINARY)\n",
    "    edges_top = cv2.Canny(thresh_top, 50, 150)\n",
    "    contours_top, _ = cv2.findContours(edges_top, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Process the front camera frame\n",
    "    gray_front = cv2.cvtColor(frame_front, cv2.COLOR_BGR2GRAY)\n",
    "    gray_front = cv2.GaussianBlur(gray_front, (21, 21), 0)\n",
    "    diff_front = cv2.absdiff(background_front_gray, gray_front)\n",
    "    _, thresh_front = cv2.threshold(diff_front, 25, 255, cv2.THRESH_BINARY)\n",
    "    edges_front = cv2.Canny(thresh_front, 50, 150)\n",
    "    contours_front, _ = cv2.findContours(edges_front, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the largest contour and bounding box for top camera\n",
    "    if contours_top:\n",
    "        largest_contour_top = max(contours_top, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour_top) > 500:  # Filter small contours\n",
    "            x_top, y_top, w_top, h_top = cv2.boundingRect(largest_contour_top)\n",
    "            # Draw bounding box and display pixel count for top camera\n",
    "            cv2.rectangle(frame_top, (x_top, y_top), (x_top + w_top, y_top + h_top), (0, 255, 0), 2)\n",
    "            pixel_count_top = w_top * h_top\n",
    "            cv2.putText(frame_top, f\"Pixels: {pixel_count_top} (W:{w_top}, H:{h_top})\",\n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Find the largest contour and bounding box for front camera\n",
    "    if contours_front:\n",
    "        largest_contour_front = max(contours_front, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour_front) > 500:  # Filter small contours\n",
    "            x_front, y_front, w_front, h_front = cv2.boundingRect(largest_contour_front)\n",
    "            # Draw bounding box and display pixel count for front camera\n",
    "            cv2.rectangle(frame_front, (x_front, y_front), (x_front + w_front, y_front + h_front), (255, 0, 0), 2)\n",
    "            pixel_count_front = w_front * h_front\n",
    "            cv2.putText(frame_front, f\"Pixels: {pixel_count_front} (W:{w_front}, H:{h_front})\",\n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "\n",
    "    # Display results\n",
    "    cv2.imshow(\"Background \",diff_top)\n",
    "    cv2.imshow(\"Background 2\",diff_front )\n",
    "    cv2.imshow(\"Edges top\",edges_top)\n",
    "    cv2.imshow(\"Edges fromt\",edges_front)\n",
    "    cv2.imshow(\"Top Camera - Bounding Box Tracking\", frame_top)\n",
    "    cv2.imshow(\"Front Camera - Bounding Box Tracking\", frame_front)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap_top.release()\n",
    "cap_front.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 112\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Program Termination \u001b[39;00m\n\u001b[0;32m    111\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple Color Detection in Real-TIme\u001b[39m\u001b[38;5;124m\"\u001b[39m, imageFrame) \n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m): \n\u001b[0;32m    113\u001b[0m     cap\u001b[38;5;241m.\u001b[39mrelease() \n\u001b[0;32m    114\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows() \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "  \n",
    "import numpy as np \n",
    "import cv2 \n",
    "  \n",
    "  \n",
    "# Capturing video through webcam \n",
    "webcam = cv2.VideoCapture(0) \n",
    "  \n",
    "# Start a while loop \n",
    "while(1): \n",
    "      \n",
    "    # Reading the video from the \n",
    "    # webcam in image frames \n",
    "    _, imageFrame = webcam.read() \n",
    "  \n",
    "    # Convert the imageFrame in  \n",
    "    # BGR(RGB color space) to  \n",
    "    # HSV(hue-saturation-value) \n",
    "    # color space \n",
    "    hsvFrame = cv2.cvtColor(imageFrame, cv2.COLOR_BGR2HSV) \n",
    "  \n",
    "    # Set range for red color and  \n",
    "    # define mask \n",
    "    red_lower = np.array([136, 87, 111], np.uint8) \n",
    "    red_upper = np.array([180, 255, 255], np.uint8) \n",
    "    red_mask = cv2.inRange(hsvFrame, red_lower, red_upper) \n",
    "  \n",
    "    # Set range for green color and  \n",
    "    # define mask \n",
    "    green_lower = np.array([25, 52, 72], np.uint8) \n",
    "    green_upper = np.array([102, 255, 255], np.uint8) \n",
    "    green_mask = cv2.inRange(hsvFrame, green_lower, green_upper) \n",
    "  \n",
    "    # Set range for blue color and \n",
    "    # define mask \n",
    "    blue_lower = np.array([94, 80, 2], np.uint8) \n",
    "    blue_upper = np.array([120, 255, 255], np.uint8) \n",
    "    blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper) \n",
    "      \n",
    "    # Morphological Transform, Dilation \n",
    "    # for each color and bitwise_and operator \n",
    "    # between imageFrame and mask determines \n",
    "    # to detect only that particular color \n",
    "    kernel = np.ones((5, 5), \"uint8\") \n",
    "      \n",
    "    # For red color \n",
    "    red_mask = cv2.dilate(red_mask, kernel) \n",
    "    res_red = cv2.bitwise_and(imageFrame, imageFrame,  \n",
    "                              mask = red_mask) \n",
    "      \n",
    "    # For green color \n",
    "    green_mask = cv2.dilate(green_mask, kernel) \n",
    "    res_green = cv2.bitwise_and(imageFrame, imageFrame, \n",
    "                                mask = green_mask) \n",
    "      \n",
    "    # For blue color \n",
    "    blue_mask = cv2.dilate(blue_mask, kernel) \n",
    "    res_blue = cv2.bitwise_and(imageFrame, imageFrame, \n",
    "                               mask = blue_mask) \n",
    "   \n",
    "    # Creating contour to track red color \n",
    "    contours, hierarchy = cv2.findContours(red_mask, \n",
    "                                           cv2.RETR_TREE, \n",
    "                                           cv2.CHAIN_APPROX_SIMPLE) \n",
    "      \n",
    "    for pic, contour in enumerate(contours): \n",
    "        area = cv2.contourArea(contour) \n",
    "        if(area > 300): \n",
    "            x, y, w, h = cv2.boundingRect(contour) \n",
    "            imageFrame = cv2.rectangle(imageFrame, (x, y),  \n",
    "                                       (x + w, y + h),  \n",
    "                                       (0, 0, 255), 2) \n",
    "              \n",
    "            cv2.putText(imageFrame, \"Red Colour\", (x, y), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, \n",
    "                        (0, 0, 255))     \n",
    "  \n",
    "    # Creating contour to track green color \n",
    "    contours, hierarchy = cv2.findContours(green_mask, \n",
    "                                           cv2.RETR_TREE, \n",
    "                                           cv2.CHAIN_APPROX_SIMPLE) \n",
    "      \n",
    "    for pic, contour in enumerate(contours): \n",
    "        area = cv2.contourArea(contour) \n",
    "        if(area > 300): \n",
    "            x, y, w, h = cv2.boundingRect(contour) \n",
    "            imageFrame = cv2.rectangle(imageFrame, (x, y),  \n",
    "                                       (x + w, y + h), \n",
    "                                       (0, 255, 0), 2) \n",
    "              \n",
    "            cv2.putText(imageFrame, \"Green Colour\", (x, y), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                        1.0, (0, 255, 0)) \n",
    "  \n",
    "    # Creating contour to track blue color \n",
    "    contours, hierarchy = cv2.findContours(blue_mask, \n",
    "                                           cv2.RETR_TREE, \n",
    "                                           cv2.CHAIN_APPROX_SIMPLE) \n",
    "    for pic, contour in enumerate(contours): \n",
    "        area = cv2.contourArea(contour) \n",
    "        if(area > 300): \n",
    "            x, y, w, h = cv2.boundingRect(contour) \n",
    "            imageFrame = cv2.rectangle(imageFrame, (x, y), \n",
    "                                       (x + w, y + h), \n",
    "                                       (255, 0, 0), 2) \n",
    "              \n",
    "            cv2.putText(imageFrame, \"Blue Colour\", (x, y), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1.0, (255, 0, 0)) \n",
    "              \n",
    "    # Program Termination \n",
    "    cv2.imshow(\"Multiple Color Detection in Real-TIme\", imageFrame) \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'): \n",
    "        cap.release() \n",
    "        cv2.destroyAllWindows() \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
